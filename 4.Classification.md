. A table below shows a sample dataset of whether a customer responds to the survey or not. “Outcome” is a class label. Construct a Decision tree classifier for the dataset. For a new example ( Rural, semidetached, low, No)  what will be the predicted class.

![Table 4.1](/Images/Table_4.1.png)

2. Brifly explain Bagging and Boosting of the Classfiers


3. Define Classification, Issues of Classification and Explain ID3 classfication with example.
Classiﬁcation is a form of data analysis that extracts models describing data classes. A classiﬁer, or classiﬁcation model,  predicts categorical  labels(classes).
Issuses
Data Cleaning
Relevance Analysis
Normalization
Generalization



ID3
	Decision tree algorithm is know as ID i.e. Iterative Dichotomiser. The ID3 algorithm begins with the original set  as the root node. On each iteration of the algorithm, it iterates through every unused attribute of the set  and calculates  the entropy  (or information gain ) of that attribute. It then selects the attribute which has the smallest entropy (or largest information gain) value. The set  is then split by the selected attribute (e.g. age is less than 50, age is between 50 and 100, age is greater than 100) to produce subsets of the data. The algorithm continues to recurse on each subset, considering only attributes never selected before.
Recursion on a subset may stop in one of these cases:
•	every element in the subset belongs to the same class (+ or -), then the node is turned into a leaf and labelled with the class of the examples
•	there are no more attributes to be selected, but the examples still do not belong to the same class (some are + and some are -), then the node is turned into a leaf and labelled with the most common class of the examples in the subset
•	there are no examples in the subset, this happens when no example in the parent set was found to be matching a specific value of the selected attribute, for example if there was no example with age >= 100. Then a leaf is created, and labelled with the most common class of the examples in the parent set.
Throughout the algorithm, the decision tree is constructed with each non-terminal node representing the selected attribute on which the data was split, and terminal nodes representing the class label of the final subset of this branch.
Properties:
ID3 does not guarantee an optimal solution; it can get stuck in local optima. It uses a greedy approach by selecting the best attribute to split the dataset on each iteration. One improvement that can be made on the algorithm can be to use backtracking during the search for the optimal decision tree.
ID3 can overfit to the training data. To avoid overfitting, smaller decision trees should be preferred over larger ones. This algorithm usually produces small trees, but it does not always produce the smallest possible tree.
ID3 is harder to use on continuous data. If the values of any given attribute is continuous, then there are many more places to split the data on this attribute, and searching for the best value to split by can be time consuming


4. Explain different methods that can be used to evaluate and compare accuracy of different classfication algorthms.


5. Use any classification techniques and find out the class of (Homeowner = Yes, Status = Employed , Income = Average)

ID,Homeowner,Status,Income, Defaulted
1,Yes,Employed,High,No,
2,No,Business,Average,NO
3,No,Employed,Low,No
4,Yes,Business,High,No
5,No,Unemployed,Average,Yes
6,No,Business,Low,No
7,Yes,Unemployed,High,No
8,No,Employed,Average,Yes
9,No,Business,Low,No
10,No,Employed,Average,Yes



6. Navie Based Classifier
Naïve Bayes classifiers are a family of simple probabilistic classifiers which assume that the effect of an attribute value on a given class is independent of the values of the other attributes. This assumption is called class conditional independence. It is made to simplify the computations involved and, in this sense, is considered “naïve”. In simple terms, a Naive Bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature.

